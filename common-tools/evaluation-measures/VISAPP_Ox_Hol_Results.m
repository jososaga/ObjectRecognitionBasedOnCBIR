%% -------------------------------------------------------------------------
% ******************************Full Size Vectors**************************
% -------------------------------------------------------------------------
%% ********************* Holidays *****************************************

% Holidays (Flickr12k): No-Dimensionality reduction (Full size vectors),
% Co-missing visual words. Full vectors were built using the training 
% dataset Flickr12k. Learning meanV_before vector on the
% learning phase, using the dataset Flickr12k
% MyR BoF-8192 -> 
%             alpha = 0    mAP: 0.
%             alpha = 0.1  mAP: 0.
%             alpha = 0.2  mAP: 0.
%             alpha = 0.3  mAP: 0.
%             alpha = 0.4  mAP: 0.
%             alpha = 0.5  mAP: 0.
%             alpha = 0.6  mAP: 0.
%             alpha = 0.7  mAP: 0.
%             alpha = 0.8  mAP: 0.
%             alpha = 0.9  mAP: 0.
%             alpha = 1.0  mAP: 0.
%             alpha = 1.2  mAP: 0.
%-------------------------------------
% MyR BoF-16384 -> 
%             alpha = 0    mAP: 0.
%             alpha = 0.1  mAP: 0.
%             alpha = 0.2  mAP: 0.
%             alpha = 0.3  mAP: 0.
%             alpha = 0.4  mAP: 0.
%             alpha = 0.5  mAP: 0.
%             alpha = 0.6  mAP: 0.
%             alpha = 0.7  mAP: 0.
%             alpha = 0.8  mAP: 0.
%             alpha = 0.9  mAP: 0.
%             alpha = 1    mAP: 0.
%             alpha = 1.2  mAP: 0.

% BoF-8192 -> 
%             alpha = 0    mAP: 0.3957
%             alpha = 0.1  mAP: 0.3959
%             alpha = 0.2  mAP: 0.3950
%             alpha = 0.3  mAP: 0.3941
%             alpha = 0.4  mAP: 0.3921
%             alpha = 0.5  mAP: 0.3905
%             alpha = 0.6  mAP: 0.3893
%             alpha = 0.7  mAP: 0.3871
%             alpha = 0.8  mAP: 0.3834
%             alpha = 0.9  mAP: 0.3781
%             alpha = 1.0  mAP: 0.3761
%             alpha = 1.2  mAP: 0.3720
%-------------------------------------
% BoF-16384 -> 
%             alpha = 0    mAP: 0.3901
%             alpha = 0.1  mAP: 0.3893
%             alpha = 0.2  mAP: 0.3875
%             alpha = 0.3  mAP: 0.3870
%             alpha = 0.4  mAP: 0.3866
%             alpha = 0.5  mAP: 0.3858
%             alpha = 0.6  mAP: 0.3854
%             alpha = 0.7  mAP: 0.3783
%             alpha = 0.8  mAP: 0.3762
%             alpha = 0.9  mAP: 0.3730
%             alpha = 1    mAP: 0.3692
%             alpha = 1.2  mAP: 0.3637

% SPM-10752 -> 
%             alpha = 0    mAP: 0.5839
%             alpha = 0.1  mAP: 0.5872
%             alpha = 0.2  mAP: 0.5860
%             alpha = 0.3  mAP: 0.5904
%             alpha = 0.4  mAP: 0.5876
%             alpha = 0.5  mAP: 0.5836
%             alpha = 0.6  mAP: 0.5840
%             alpha = 0.7  mAP: 0.5704
%             alpha = 0.8  mAP: 0.5597
%             alpha = 0.9  mAP: 0.5447
%             alpha = 1.0  mAP: 0.5365
%             alpha = 1.2  mAP: 0.5085
%-------------------------------------
% SPM-16128 -> 
%             alpha = 0    mAP: 0.5998
%             alpha = 0.1  mAP: 0.6012
%             alpha = 0.2  mAP: 0.6020
%             alpha = 0.3  mAP: 0.6046
%             alpha = 0.4  mAP: 0.6059
%             alpha = 0.5  mAP: 0.6048
%             alpha = 0.6  mAP: 0.6028
%             alpha = 0.7  mAP: 0.5941
%             alpha = 0.8  mAP: 0.5848
%             alpha = 0.9  mAP: 0.5691
%             alpha = 1    mAP: 0.5507
%             alpha = 1.2  mAP: 0.5224

%-------------------------------------
% MyR-BoF-4096 -> 
%             alpha = 0    mAP: 0.6206 *
%             alpha = 0.1  mAP: 0.
%             alpha = 0.2  mAP: 0.
%             alpha = 0.3  mAP: 0. *
%             alpha = 0.4  mAP: 0. *
%             alpha = 0.5  mAP: 0.
%             alpha = 0.6  mAP: 0.
%             alpha = 0.7  mAP: 0.
%             alpha = 0.8  mAP: 0.
%             alpha = 0.9  mAP: 0.
%             alpha = 1    mAP: 0.
%             alpha = 1.2  mAP: 0. *

% VLAD-8192 -> 
%             alpha = 0    mAP: 0.5288
% VLAD SSR-8192 -> 
%             alpha = 0    mAP: 0.5941
%-------------------------------------
% VLAD-16384 -> 
%             alpha = 0    mAP: 0.5474
% VLAD SSR-16384 -> 
%             alpha = 0    mAP: 0.6207


%% ********************* Oxford *******************************************

% Oxford (Paris6k): No-Dimensionality reduction (Full size vectors),
% Co-missing visual words. Full vectors were built using the training 
% dataset Paris6k. Learning meanV_before vector on the
% learning phase, using the dataset Paris6K
% BoF-8192 -> 
%             alpha = 0    mAP: 0.1174
%             alpha = 0.1  mAP: 0.1174
%             alpha = 0.2  mAP: 0.1175
%             alpha = 0.3  mAP: 0.1175
%             alpha = 0.4  mAP: 0.1173
%             alpha = 0.5  mAP: 0.1173
%             alpha = 0.6  mAP: 0.1165
%             alpha = 0.7  mAP: 0.1163
%             alpha = 0.8  mAP: 0.1162
%             alpha = 0.9  mAP: 0.1163
%             alpha = 1.0  mAP: 0.1158
%             alpha = 1.2  mAP: 0.1156
%-------------------------------------
% BoF-16384 -> 
%             alpha = 0    mAP: 0.1179
%             alpha = 0.1  mAP: 0.1178
%             alpha = 0.2  mAP: 0.1176
%             alpha = 0.3  mAP: 0.1174
%             alpha = 0.4  mAP: 0.1171
%             alpha = 0.5  mAP: 0.1167
%             alpha = 0.6  mAP: 0.1164
%             alpha = 0.7  mAP: 0.1161
%             alpha = 0.8  mAP: 0.1160
%             alpha = 0.9  mAP: 0.1159
%             alpha = 1    mAP: 0.1156
%             alpha = 1.2  mAP: 0.1155

% SPM-10752 -> 
%             alpha = 0    mAP: 0.3255
%             alpha = 0.1  mAP: 0.3291
%             alpha = 0.2  mAP: 0.3316
%             alpha = 0.3  mAP: 0.3358
%             alpha = 0.4  mAP: 0.3396
%             alpha = 0.5  mAP: 0.3429
%             alpha = 0.6  mAP: 0.3458
%             alpha = 0.7  mAP: 0.3465
%             alpha = 0.8  mAP: 0.3479
%             alpha = 0.9  mAP: 0.3469
%             alpha = 1.0  mAP: 0.3421
%             alpha = 1.2  mAP: 0.3301
%-------------------------------------
% SPM-16128 -> 
%             alpha = 0    mAP: 0.3439
%             alpha = 0.1  mAP: 0.3472
%             alpha = 0.2  mAP: 0.3514
%             alpha = 0.3  mAP: 0.3556
%             alpha = 0.4  mAP: 0.3610
%             alpha = 0.5  mAP: 0.3642
%             alpha = 0.6  mAP: 0.3677
%             alpha = 0.7  mAP: 0.3670
%             alpha = 0.8  mAP: 0.3655
%             alpha = 0.9  mAP: 0.3625
%             alpha = 1    mAP: 0.3569
%             alpha = 1.2  mAP: 0.3472

%-------------------------------------
% MyR-BoF-4096 -> 
%             alpha = 0    mAP: 0. *
%             alpha = 0.1  mAP: 0.
%             alpha = 0.2  mAP: 0.
%             alpha = 0.3  mAP: 0. 
%             alpha = 0.4  mAP: 0. 
%             alpha = 0.5  mAP: 0.
%             alpha = 0.6  mAP: 0.
%             alpha = 0.7  mAP: 0.
%             alpha = 0.8  mAP: 0.
%             alpha = 0.9  mAP: 0.
%             alpha = 1    mAP: 0.
%             alpha = 1.2  mAP: 0. *

% VLAD-8192 -> 
%             alpha = 0    mAP: 0.2398
% VLAD SSR-8192 -> 
%             alpha = 0    mAP: 0.3211
%-------------------------------------
% VLAD-16384 -> 
%             alpha = 0    mAP: 0.2660
% VLAD SSR-16384 -> 
%             alpha = 0    mAP: 0.3658

%% -------------------------------------------------------------------------
% ******************************Short Size Vectors**************************
% -------------------------------------------------------------------------

% Holidays (Flickr12k): Dimensionality reduction (PCA and Whitening). 
% Full vectors were built using the training dataset Flickr12k. Learning 
% PCA and Whitening vectors on the learning phase, using the dataset 
% Flickr12k. Dimension = 128.
%
% BoF-8192   -> mAP = 0.3766
% BoF-16384  -> mAP = 0.3880
%-------------------------------------
% SPM-10752  -> mAP = 0.5990
% SPM-16128  -> mAP = 0.6201
%-------------------------------------
% VLAD-8192  -> mAP = 0.5540
% VLAD-16384 -> mAP = 0.5535
%-------------------------------------
% MyR-BoF-8192  -> mAP = 0.639
% MyR-BoF-16384 -> mAP = 0.665


% Oxford (Paris6k): Dimensionality reduction (PCA and Whitening). 
% Full vectors were built using the training dataset Paris6k. Learning 
% PCA and Whitening vectors on the learning phase, using the dataset 
% Paris6k. Dimension = 128.
%
% BoF-8192   -> mAP = 0.1228
% BoF-16384  -> mAP = 0.1227
%-------------------------------------
% SPM-10752  -> mAP = 0.3125
% SPM-16128  -> mAP = 0.3262
%-------------------------------------
% VLAD-8192  -> mAP = 0.2740
% VLAD-16384 -> mAP = 0.2663
%-------------------------------------
% MyR-BoF-8192  -> mAP = 0.317
% MyR-BoF-16384 -> mAP = 0.331

%% Show the Results


